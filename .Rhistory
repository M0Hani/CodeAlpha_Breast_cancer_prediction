coord_polar(theta = "y") +
geom_text(aes(label = paste0(round(Proportion * 100), "%")),
position = position_stack(vjust = 0.5)) +
labs(fill = "Category")
barplot(table(dfcat$diagnose))
ggplot(dfcat, aes(x = diagnose)) +
geom_bar()
#Pie chart
counts <- table(dfcat$diagnose)
propor <- counts / sum(counts)
pie_data <- data.frame( cls <- names(propor),
Prop <- propor)
ggplot(pie_data, aes(x = "", y = Prop, fill = cls)) +
geom_bar(stat = "identity", width = 1) + coord_polar(theta = "y") +
geom_text(aes(label = paste0(round(Prop * 100), "%")),
position = position_stack(vjust = 0.5)) + labs(fill = "Category")
#Bar plot
bar_ <- data.frame(cls <- names(table(dfcat$diagnose)), count <- table(dfcat$diagnose))
ggplot(bar_, aes(x = cls, y = count)) +
geom_bar(stat = "identity") +
geom_text(aes(label = count), vjust = -0.5) +
xlab("Category") +
ylab("Count") +
ggtitle("Bar Plot of Category Counts")
#Pie chart
counts <- table(dfcat$diagnose)
propor <- counts / sum(counts)
pie_ <- data.frame( cls <- names(propor), Prop <- propor)
ggplot(pie_, aes(x = "", y = Prop, fill = cls)) +
geom_bar(stat = "identity", width = 1) + coord_polar(theta = "y") +
geom_text(aes(label = paste0(round(Prop * 100), "%")),
position = position_stack(vjust = 0.5)) + labs(fill = "Category")
counts <- table(dfcat$diagnose)
perc <- counts / sum(counts)
pie_ <- data.frame( cls <- names(perc), Prop <- perc)
ggplot(pie_, aes(x = "", y = Prop, fill = cls)) +
geom_bar(stat = "identity", width = 1) + coord_polar(theta = "y") +
geom_text(aes(label = paste0(round(Prop * 100), "%")),
position = position_stack(vjust = 0.5)) + labs(fill = "Category")
#Pie chart
counts <- table(dfcat$diagnose)
perc <- counts / sum(counts)
pie_ <- data.frame( cls <- names(perc), Prop <- perc)
ggplot(pie_, aes(x = "", y = Prop, fill = cls)) +
geom_bar(stat = "identity", width = 1) + coord_polar(theta = "y") +
geom_text(aes(label = paste0(round(Prop * 100), "%")),
position = position_stack(vjust = 0.5)) + labs(fill = "Class")
#Bar plot
#Pie chart
counts <- table(dfcat$diagnose)
perc <- counts / sum(counts)
pie_ <- data.frame( cls <- names(perc), Prop <- perc)
ggplot(pie_, aes(x = "", y = Prop, fill = cls)) +
geom_bar(stat = "identity", width = 1) + coord_polar(theta = "Percentage") +
geom_text(aes(label = paste0(round(Prop * 100), "%")),
position = position_stack(vjust = 0.5)) + labs(fill = "Class")
#Pie chart
counts <- table(dfcat$diagnose)
perc <- counts / sum(counts)
pie_ <- data.frame( cls <- names(perc), Percentage <- perc)
ggplot(pie_, aes(x = "", y = Percentage, fill = cls)) +
geom_bar(stat = "identity", width = 1) + coord_polar(theta = "y") +
geom_text(aes(label = paste0(round(Percentage * 100), "%")),
position = position_stack(vjust = 0.5)) + labs(fill = "Class")
#Bar plot
#Bar plot
bar_ <- data.frame(cls <- names(table(dfcat$diagnose)), count <- table(dfcat$diagnose))
ggplot(bar_, aes(x = cls, y = count)) +
geom_bar(stat = "identity") +
geom_text(aes(label = count), vjust = -0.5) +
xlab("Class") + ylab("Count") +
ggtitle("Bar plot of Diagnoses")
library(treemap)
install.packages("treemap")
library(treemap)
treemap(data, index = "Category", vSize = "Count")
library(treemap)
treemap(dfcat, index = "Category", vSize = "Count")
treemap(dfcat, index = "diagnose", vSize = "Count")
#Bar plot
bar_ <- data.frame(cls <- names(counts), count <- counts)
ggplot(bar_, aes(x = cls, y = count)) +
geom_bar(stat = "identity") +
geom_text(aes(label = count), vjust = -0.5) +
xlab("Class") + ylab("Count") +
ggtitle("Bar plot of Diagnoses")
install.packages("ggridges")
install.packages("ggridges")
library(ggridges)
library(treemap)
treemap(dfcat, index = "diagnose", vSize = "counts")
treemap(dfcat, index = "diagnose", vSize = "diagnose")
treemap(dfcat, index = "diagnose", vSize = "table(dfcat$diagnose)")
# Importing libraries to use
library(tidyverse)
library(caret)
library(e1071)
library(rpart)
library(randomForest)
library(gplots)
library(ggplot2)
library(reshape2)
library(dplyr)
#==================================================================
# Reading data
df <- data.frame(read.csv("BreastCancer.csv"))
#==================================================================
# Data pre-processing
str(df)
summary(df)
null_values <- colSums(is.na(df))
print(null_values) #no null values
df <- unique(df) #dropping duplicates
rownames(df) <- NULL #re-indexing
str(df)
dfcat <- data.frame(lapply(df, as.factor))
dfcat$diagnose <- recode(dfcat$diagnose, "1" = "Malignant", "0" = "Benign")
#splitting data into inputs and target
inputs <- df[,-10]
target <- df[,10]
print(inputs)
print(target)
#==================================================================
# Visualizing data
#Pie chart
counts <- table(dfcat$diagnose)
perc <- counts / sum(counts)
pie_ <- data.frame( cls <- names(perc), Percentage <- perc)
ggplot(pie_, aes(x = "", y = Percentage, fill = cls)) +
geom_bar(stat = "identity", width = 1) + coord_polar(theta = "y") +
geom_text(aes(label = paste0(round(Percentage * 100), "%")),
position = position_stack(vjust = 0.5)) + labs(fill = "Class")
#Bar plot
bar_ <- data.frame(cls <- names(counts), count <- counts)
ggplot(bar_, aes(x = cls, y = count)) +
geom_bar(stat = "identity") +
geom_text(aes(label = count), vjust = -0.5) +
xlab("Class") + ylab("Count") +
ggtitle("Bar plot of Diagnoses")
#Heat-map
cor_data <- reshape2::melt(cor(df))
ggplot(cor_data, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() + geom_text(aes(label = round(value, 2), x = Var1, y = Var2),
hjust = 0.5, vjust = 0.5, size = 2) +
scale_fill_gradient2(low = "#D73027", mid = "#FEE090", high = "#4575B4",
midpoint = 0, limits = c(-1, 1), name = "Correlation") +
theme_minimal() + coord_equal() + labs(title = "Heatmap", x = "", y = "") +
theme(axis.text.x = element_text(angle = 90))
set.seed(123)
trainIndex <- createDataPartition(target, p = 0.7, list = FALSE)
trainX <- inputs[trainIndex, ]
trainY <- target[trainIndex]
testX <- inputs[-trainIndex, ]
testY <- target[-trainIndex]
# 1. Support Vector Machines (SVM)
svm_model <- svm(trainX, trainY)
svm_predictions <- predict(svm_model, testX)
svm_accuracy <- confusionMatrix(svm_predictions, testY)$overall['Accuracy']
set.seed(123)
trainIndex <- createDataPartition(target, p = 0.7, list = FALSE)
trainX <- inputs[trainIndex, ]
trainY <- target[trainIndex]
testX <- inputs[-trainIndex, ]
testY <- target[-trainIndex]
# Model training and evaluation
# 1. Support Vector Machines (SVM)
svm_model <- svm(trainX, trainY)
svm_predictions <- predict(svm_model, testX)
svm_accuracy <- confusionMatrix(svm_predictions, testY)$overall['Accuracy']
# 3. Random Forest
rf_model <- randomForest(trainX, trainY)
rf_predictions <- predict(rf_model, testX)
rf_accuracy <- confusionMatrix(rf_predictions, testY)$overall['Accuracy']
# Prepare for modeling
set.seed(123)
trainIndex <- createDataPartition(target, p = 0.7)
trainX <- inputs[trainIndex, ]
# Prepare for modeling
set.seed(123)
trainIndex <- createDataPartition(target, p = 0.7, list = FALSE)
trainX <- inputs[trainIndex, ]
trainY <- target[trainIndex,]
set.seed(123)
trainIndex <- createDataPartition(target, p = 0.7, list = FALSE)
trainX <- inputs[trainIndex, ]
trainY <- target[trainIndex]
testX <- inputs[-trainIndex, ]
testY <- target[-trainIndex]
# 1. Support Vector Machines (SVM)
svm_model <- svm(trainX, trainY)
svm_predictions <- predict(svm_model, testX)
svm_accuracy <- confusionMatrix(svm_predictions, testY)$overall['Accuracy']
set.seed(123)
train_index <- createDataPartition(target, p = 0.7, list = FALSE)
train_data <- df[train_index, ]
test_data <- df[-train_index, ]
inputs <- dfcat[,-10]
target <- dfcat[,10]
print(inputs)
print(target)
set.seed(123)
trainIndex <- createDataPartition(target, p = 0.7, list = FALSE)
trainX <- inputs[trainIndex, ]
trainY <- target[trainIndex]
testX <- inputs[-trainIndex, ]
testY <- target[-trainIndex]
# 1. Support Vector Machines (SVM)
svm_model <- svm(trainX, trainY)
inputs <- df[,-10]
target <- dfcat[,10]
set.seed(123)
trainIndex <- createDataPartition(target, p = 0.7, list = FALSE)
trainX <- inputs[trainIndex, ]
trainY <- target[trainIndex]
testX <- inputs[-trainIndex, ]
testY <- target[-trainIndex]
svm_model <- svm(trainX, trainY)
svm_predictions <- predict(svm_model, testX)
svm_accuracy <- confusionMatrix(svm_predictions, testY)$overall['Accuracy']
# 3. Random Forest
rf_model <- randomForest(trainX, trainY)
rf_predictions <- predict(rf_model, testX)
rf_accuracy <- confusionMatrix(rf_predictions, testY)$overall['Accuracy']
cat("Support Vector Machines (SVM) Accuracy:", svm_accuracy, "\n")
#cat("Decision Tree (CART) Accuracy:", cart_accuracy, "\n")
cat("Random Forest Accuracy:", rf_accuracy, "\n")
cart_model <- rpart(trainX, trainY)
set.seed(123)
trainIndex <- createDataPartition(target, p = 0.7, list = FALSE)
trainX <- df[trainIndex, -10]
trainY <- dfcat[trainIndex, 10]
testX <- df[-trainIndex, -10]
testY <- dfcat[-trainIndex, 10]
svm_model <- svm(trainX, trainY)
svm_predictions <- predict(svm_model, testX)
svm_accuracy <- confusionMatrix(svm_predictions, testY)$overall['Accuracy']
# 2. Decision Tree (CART)
cart_model <- rpart(trainX, trainY)
# 3. Random Forest
rf_model <- randomForest(trainX, trainY)
rf_predictions <- predict(rf_model, testX)
rf_accuracy <- confusionMatrix(rf_predictions, testY)$overall['Accuracy']
cat("Support Vector Machines (SVM) Accuracy:", svm_accuracy, "\n")
#cat("Decision Tree (CART) Accuracy:", cart_accuracy, "\n")
cat("Random Forest Accuracy:", rf_accuracy, "\n")
cart_model <- rpart(trainX, trainY)
set.seed(123)
trainIndex <- createDataPartition(target, p = 0.7, list = FALSE)
trainX <- df[trainIndex, -10]
trainY <- dfcat[trainIndex, 10]
testX <- df[-trainIndex, -10]
testY <- dfcat[-trainIndex, 10]
art_model <- rpart(trainX, trainY)
set.seed(123)
trainIndex <- createDataPartition(target, p = 0.7, list = FALSE)
trainX <- dfcat[trainIndex, -10]
trainY <- dfcat[trainIndex, 10]
testX <- dfcat[-trainIndex, -10]
testY <- dfcat[-trainIndex, 10]
# 2. Decision Tree (CART)
cart_model <- rpart(trainX, trainY)
# Prepare for modeling
set.seed(123)
trainIndex <- createDataPartition(target, p = 0.7, list = FALSE)
trainX <- df[trainIndex, -10]
trainY <- dfcat[trainIndex, 10]
testX <- df[-trainIndex, -10]
testY <- dfcat[-trainIndex, 10]
# Model training and evaluation
# 1. Support Vector Machines (SVM)
svm_model <- svm(trainX, trainY)
svm_predictions <- predict(svm_model, testX)
svm_accuracy <- confusionMatrix(svm_predictions, testY)$overall['Accuracy']
# 2. Decision Tree (CART)
cart_model <- rpart(trainX, trainY)
# 3. Random Forest
rf_model <- randomForest(trainX, trainY)
rf_predictions <- predict(rf_model, testX)
rf_accuracy <- confusionMatrix(rf_predictions, testY)$overall['Accuracy']
set.seed(123)
train_indices <- sample(1:nrow(df), nrow(df)*0.7)
train_data <- df[train_indices, ]
test_data <- df[-train_indices, ]
cart_model <- rpart(diagnose ~ ., data = train_data)
predictions <- predict(cart_model, newdata = test_data, type = "class")
set.seed(123)
train_indices <- sample(1:nrow(dfcat), nrow(dfcat)*0.7)
train_data <- dfcat[train_indices, ]
test_data <- dfcat[-train_indices, ]
# 2. Decision Tree (CART)
cart_model <- rpart(diagnose ~ ., data = train_data)
predictions <- predict(cart_model, newdata = test_data, type = "class")
confusionMatrix(predictions, test_data$diagnose)
set.seed(123)
train_indices <- sample(1:nrow(dfcat), nrow(dfcat)*0.7)
train_data <- dfcat[train_indices, ]
test_data <- dfcat[-train_indices, ]
# 2. Decision Tree (CART)
cart_model <- rpart(diagnose ~ ., data = train_data)
train_predictions <- predict(cart_model, newdata = train_data, type = "class")
test_predictions <- predict(cart_model, newdata = test_data, type = "class")
train_accuracy <- sum(train_predictions == train_data$diagnose) / length(train_predictions)
test_accuracy <- sum(test_predictions == test_data$diagnose) / length(test_predictions)
cat("Training Accuracy:", train_accuracy, "\n")
cat("Testing Accuracy:", test_accuracy, "\n")
# 3. Random Forest
rf_model <- randomForest(diagnose ~ ., data = train_data)
rf_trn_pred <- predict(rf_model, newdata = train_data)
rf_tst_pred<- predict(rf_model, newdata = test_data)
rf_trn_acc <- sum(rf_trn_pred == train_data$diagnose) / length(rf_trn_pred)
rf_tst_acc <- sum(rf_tst_pred == test_data$diagnose) / length(rf_tst_pred)
# Prepare for modeling
set.seed(123)
train_indices <- sample(1:nrow(dfcat), nrow(dfcat)*0.7)
train_data <- dfcat[train_indices, ]
test_data <- dfcat[-train_indices, ]
# Model training and evaluation
# 1. Support Vector Machines (SVM)
svm_model <- svm(diagnose ~ ., data = train_data)
svm_trn_pred <- predict(svm_model, newdata = train_data)
svm_tst_pred <- predict(svm_model, newdata = test_data)
svm_trn_acc <- sum(svm_trn_pred == train_data$diagnose) / length(svm_trn_pred)
svm_tst_acc <- sum(svm_tst_pred == test_data$diagnose) / length(svm_tst_pred)
# 2. Decision Tree (CART)
dt_model <- rpart(diagnose ~ ., data = train_data)
dt_trn_pred <- predict(dt_model, newdata = train_data)
dt_tst_pred <- predict(dt_model, newdata = test_data)
dt_trn_acc <- sum(dt_trn_pred == train_data$diagnose) / length(dt_trn_pred)
dt_tst_acc <- sum(dt_tst_pred == test_data$diagnose) / length(dt_tst_pred)
# 3. Random Forest
rf_model <- randomForest(diagnose ~ ., data = train_data)
rf_trn_pred <- predict(rf_model, newdata = train_data)
rf_tst_pred<- predict(rf_model, newdata = test_data)
rf_trn_acc <- sum(rf_trn_pred == train_data$diagnose) / length(rf_trn_pred)
rf_tst_acc <- sum(rf_tst_pred == test_data$diagnose) / length(rf_tst_pred)
# Print the accuracies
cat("SVM - Training Accuracy:", svm_trn_acc, "\n")
cat("SVM - Testing Accuracy:", svm_tst_acc, "\n")
cat("Decision Tree - Training Accuracy:", dt_trn_acc, "\n")
cat("Decision Tree - Testing Accuracy:", dt_tst_acc, "\n")
cat("Random Forest - Training Accuracy:", rf_trn_acc, "\n")
cat("Random Forest - Testing Accuracy:", rf_tst_acc, "\n")
# 2. Decision Tree (CART)
dt_model <- rpart(diagnose ~ ., data = train_data)
dt_trn_pred <- predict(dt_model, newdata = train_data, type = "class")
dt_tst_pred <- predict(dt_model, newdata = test_data, type = "class")
dt_trn_acc <- sum(dt_trn_pred == train_data$diagnose) / length(dt_trn_pred)
dt_tst_acc <- sum(dt_tst_pred == test_data$diagnose) / length(dt_tst_pred)
cat("Decision Tree - Training Accuracy:", dt_trn_acc, "\n")
cat("Decision Tree - Testing Accuracy:", dt_tst_acc, "\n")
# Prepare for modeling
set.seed(123)
train_indices <- sample(1:nrow(dfcat), nrow(dfcat)*0.7)
train_data <- dfcat[train_indices, ]
test_data <- dfcat[-train_indices, ]
# Model training and evaluation
# 1. Support Vector Machines (SVM)
svm_model <- svm(diagnose ~ ., data = train_data)
svm_trn_pred <- predict(svm_model, newdata = train_data)
svm_tst_pred <- predict(svm_model, newdata = test_data)
svm_trn_acc <- sum(svm_trn_pred == train_data$diagnose) / length(svm_trn_pred)
svm_tst_acc <- sum(svm_tst_pred == test_data$diagnose) / length(svm_tst_pred)
# 2. Decision Tree (CART)
dt_model <- rpart(diagnose ~ ., data = train_data)
dt_trn_pred <- predict(dt_model, newdata = train_data, type = "class")
dt_tst_pred <- predict(dt_model, newdata = test_data, type = "class")
dt_trn_acc <- sum(dt_trn_pred == train_data$diagnose) / length(dt_trn_pred)
dt_tst_acc <- sum(dt_tst_pred == test_data$diagnose) / length(dt_tst_pred)
# 3. Random Forest
rf_model <- randomForest(diagnose ~ ., data = train_data)
rf_trn_pred <- predict(rf_model, newdata = train_data)
rf_tst_pred<- predict(rf_model, newdata = test_data)
rf_trn_acc <- sum(rf_trn_pred == train_data$diagnose) / length(rf_trn_pred)
rf_tst_acc <- sum(rf_tst_pred == test_data$diagnose) / length(rf_tst_pred)
# Print the accuracies
cat("SVM - Training Accuracy:", svm_trn_acc, "\n")
cat("SVM - Testing Accuracy:", svm_tst_acc, "\n")
cat("Decision Tree - Training Accuracy:", dt_trn_acc, "\n")
cat("Decision Tree - Testing Accuracy:", dt_tst_acc, "\n")
cat("Random Forest - Training Accuracy:", rf_trn_acc, "\n")
cat("Random Forest - Testing Accuracy:", rf_tst_acc, "\n")
# 3. Random Forest
rf_model <- randomForest(diagnose ~ ., data = train_data)
rf_trn_pred <- predict(rf_model, newdata = train_data, type = "class")
rf_tst_pred<- predict(rf_model, newdata = test_data, type = "class")
rf_trn_acc <- sum(rf_trn_pred == train_data$diagnose) / length(rf_trn_pred)
rf_tst_acc <- sum(rf_tst_pred == test_data$diagnose) / length(rf_tst_pred)
cat("Random Forest - Training Accuracy:", rf_trn_acc, "\n")
cat("Random Forest - Testing Accuracy:", rf_tst_acc, "\n")
# 4. Neural Network
nn_model <- neuralnet(diagnose ~ ., data = train_data, hidden = 10)
library(nn)
install.packages("nn")
install.packages("keras")
library(keras)
# 4. Neural Network
nn_model <- neuralnet(diagnose ~ ., data = train_data, hidden = 10)
install.packages("neuralnet")
library(neuralnet)
# 4. Neural Network
nn_model <- neuralnet(diagnose ~ ., data = train_data, hidden = 10)
library(neuralnet)
# 4. Neural Network
nn_model <- neuralnet(diagnose ~ ., data = train_data, hidden = 10)
# Prepare for modeling
set.seed(123)
train_indices <- sample(1:nrow(dfcat), nrow(dfcat)*0.7)
train_data <- dfcat[train_indices, ]
test_data <- dfcat[-train_indices, ]
# Model training and evaluation
# 1. Support Vector Machines (SVM)
svm_model <- svm(diagnose ~ ., data = train_data)
svm_trn_pred <- predict(svm_model, newdata = train_data)
svm_tst_pred <- predict(svm_model, newdata = test_data)
svm_trn_acc <- sum(svm_trn_pred == train_data$diagnose) / length(svm_trn_pred)
svm_tst_acc <- sum(svm_tst_pred == test_data$diagnose) / length(svm_tst_pred)
# 2. Decision Tree (CART)
dt_model <- rpart(diagnose ~ ., data = train_data)
dt_trn_pred <- predict(dt_model, newdata = train_data, type = "class")
dt_tst_pred <- predict(dt_model, newdata = test_data, type = "class")
dt_trn_acc <- sum(dt_trn_pred == train_data$diagnose) / length(dt_trn_pred)
dt_tst_acc <- sum(dt_tst_pred == test_data$diagnose) / length(dt_tst_pred)
# 3. Random Forest
rf_model <- randomForest(diagnose ~ ., data = train_data)
rf_trn_pred <- predict(rf_model, newdata = train_data)
rf_tst_pred<- predict(rf_model, newdata = test_data)
rf_trn_acc <- sum(rf_trn_pred == train_data$diagnose) / length(rf_trn_pred)
rf_tst_acc <- sum(rf_tst_pred == test_data$diagnose) / length(rf_tst_pred)
# 4. Neural Network
nn_model <- neuralnet(diagnose ~ ., data = train_data, hidden = 10)
# Importing libraries to use
library(tidyverse)
library(gplots)
library(ggplot2)
library(reshape2)
library(dplyr)
library(caret)
library(e1071)
library(rpart)
library(randomForest)
#==================================================================
# Reading data
df <- data.frame(read.csv("BreastCancer.csv"))
#==================================================================
# Data pre-processing
str(df)
summary(df)
null_values <- colSums(is.na(df))
print(null_values) #no null values
df <- unique(df) #dropping duplicates
rownames(df) <- NULL #re-indexing
str(df)
dfcat <- data.frame(lapply(df, as.factor))
dfcat$diagnose <- recode(dfcat$diagnose, "1" = "Malignant", "0" = "Benign")
#==================================================================
# Visualizing data
#Pie chart
counts <- table(dfcat$diagnose)
perc <- counts / sum(counts)
pie_ <- data.frame( cls <- names(perc), Percentage <- perc)
ggplot(pie_, aes(x = "", y = Percentage, fill = cls)) +
geom_bar(stat = "identity", width = 1) + coord_polar(theta = "y") +
geom_text(aes(label = paste0(round(Percentage * 100), "%")),
position = position_stack(vjust = 0.5)) + labs(fill = "Class")
#Bar plot
bar_ <- data.frame(cls <- names(counts), count <- counts)
ggplot(bar_, aes(x = cls, y = count)) +
geom_bar(stat = "identity") +
geom_text(aes(label = count), vjust = -0.5) +
xlab("Class") + ylab("Count") +
ggtitle("Bar plot of Diagnoses")
#Heat-map
cor_data <- reshape2::melt(cor(df))
ggplot(cor_data, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() + geom_text(aes(label = round(value, 2), x = Var1, y = Var2),
hjust = 0.5, vjust = 0.5, size = 2) +
scale_fill_gradient2(low = "#D73027", mid = "#FEE090", high = "#4575B4",
midpoint = 0, limits = c(-1, 1), name = "Correlation") +
theme_minimal() + coord_equal() + labs(title = "Heatmap", x = "", y = "") +
theme(axis.text.x = element_text(angle = 90))
#==================================================================
# Prepare for modeling
set.seed(123)
train_indices <- sample(1:nrow(dfcat), nrow(dfcat)*0.7)
train_data <- dfcat[train_indices, ]
test_data <- dfcat[-train_indices, ]
# Model training and evaluation
# 1. Support Vector Machines (SVM)
svm_model <- svm(diagnose ~ ., data = train_data)
svm_trn_pred <- predict(svm_model, newdata = train_data)
svm_tst_pred <- predict(svm_model, newdata = test_data)
svm_trn_acc <- sum(svm_trn_pred == train_data$diagnose) / length(svm_trn_pred)
svm_tst_acc <- sum(svm_tst_pred == test_data$diagnose) / length(svm_tst_pred)
# 2. Decision Tree (CART)
dt_model <- rpart(diagnose ~ ., data = train_data)
dt_trn_pred <- predict(dt_model, newdata = train_data, type = "class")
dt_tst_pred <- predict(dt_model, newdata = test_data, type = "class")
dt_trn_acc <- sum(dt_trn_pred == train_data$diagnose) / length(dt_trn_pred)
dt_tst_acc <- sum(dt_tst_pred == test_data$diagnose) / length(dt_tst_pred)
# 3. Random Forest
rf_model <- randomForest(diagnose ~ ., data = train_data)
rf_trn_pred <- predict(rf_model, newdata = train_data)
rf_tst_pred<- predict(rf_model, newdata = test_data)
rf_trn_acc <- sum(rf_trn_pred == train_data$diagnose) / length(rf_trn_pred)
rf_tst_acc <- sum(rf_tst_pred == test_data$diagnose) / length(rf_tst_pred)
# Print the accuracies
cat("SVM - Training Accuracy:", svm_trn_acc, "\n")
cat("SVM - Testing Accuracy:", svm_tst_acc, "\n")
cat("Decision Tree - Training Accuracy:", dt_trn_acc, "\n")
cat("Decision Tree - Testing Accuracy:", dt_tst_acc, "\n")
cat("Random Forest - Training Accuracy:", rf_trn_acc, "\n")
cat("Random Forest - Testing Accuracy:", rf_tst_acc, "\n")
